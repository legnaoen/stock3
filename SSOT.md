# SSOT – 주식 시장 데이터 자동 분석·추천 시스템

> **[중요] 이 문서는 항상 시스템 명령어 `date "+%Y-%m-%d"`로 오늘 날짜를 확인하여 기록/갱신합니다. (수동/추론/하드코딩 금지)**

---
> **🎯 이 문서의 목적**: AI와의 바이브코딩에서 맥락 유지, 불필요한 코드 재작성 방지, 안정적 기능 보호

## 프로젝트 계획

### 1. 과제명
- 주식 시장 데이터 자동 수집·분석·추천 시스템 (MVP)
- (확장형 AI 기반 투자 리서치 플랫폼 기초 구축)

### 2. 목표 및 개요
- 국내 주식 시장의 모든 종목에 대한 가격, 거래량, 업종·테마, 재무, 뉴스 등 핵심 데이터를 자동으로 수집 및 가공
- 업종/테마 트렌드, 주도주, 주요 이슈, 투자 매력도 등 실전 투자 인사이트를 자동 리포트 형태로 제공
- LLM 등 AI 분석 연계 및 SaaS 사업화가 가능한 모듈형 데이터 인프라 설계/구축

#### 핵심 가치
- 실전 투자 자동화 리서치: 시장 흐름과 종목 특징을 자동 분석, 투자 의사결정 정보 신속 제공
- 데이터/분석 API 기반: 외부 시스템/사용자에 API 형태로 데이터·분석 결과 제공
- 유연한 확장성: MVP 이후 단계적 기능 확장(개인화, 전략 백테스트, 외부 연동 등)에 최적화된 구조

### 3. MVP 단계 주요 기능 및 구성
- **DB 중심 파이프라인:** 모든 데이터는 즉시 DB에 저장, 각 모듈은 DB에서 읽고 결과도 DB에 저장
- **데이터 수집:** 종목정보, 업종/테마, 시세, 재무, 뉴스 등 다양한 소스(PyKRX, DART, Selenium 등)에서 자동 수집
- **분석/가공:** 업종/테마별 등락률, 주도주 추출, 이슈 매핑/요약, 투자매력 점수화 등
- **LLM 연동:** DB 기반 질의응답, 뉴스/이슈 요약, 투자 인사이트 자동화
- **확장성:** 각 기능은 독립 모듈, DB 중심, 스케줄러/컨테이너화, API 제공 등

## 1. 프로젝트 개요

- **목적:** 국내 주식 시장의 모든 종목에 대한 가격, 거래량, 업종·테마, 재무, 뉴스 등 핵심 데이터를 자동으로 수집·가공하고, 실전 투자에 필요한 인사이트(업종/테마 트렌드, 주도주, 주요 이슈, 투자 매력도 등)를 자동 리포트 형태로 제공
- **배경:** 데이터 기반 실전 투자 자동화, LLM 등 AI 분석 연계 및 SaaS 사업화까지 확장 가능한 모듈형 데이터 인프라 구축
- **주요 기능:**
  1. DB 중심 데이터 수집 파이프라인 (PyKRX, DART, Selenium 등)
  2. 업종/테마/주도주/이슈/투자매력도 등 자동 분석 및 점수화
  3. LLM 연동 질의응답/자동 리포트/뉴스 요약
  4. API/외부 연동 및 확장성 지원
- **적용 범위:** 국내 상장주식 전체, 실전 투자자/리서치/AI 서비스 등
- **신경 쓸 점:** 
  - 모든 데이터/분석 결과는 반드시 DB(SSOT)에 저장, 각 모듈은 DB에서 읽고 결과도 DB에 저장
  - 크롤링 소스(네이버 등) 변경에 취약, 주기적 모니터링 및 유지보수 필요
  - API/LLM 사용량/비용 관리, 데이터 신뢰도 검증 자동화
- **협업자/관리자:** [작성자명]

---

## 2. 바이브 코딩 운영·실행 지침

1. 작업은 "부분 수정/최소 변경"을 원칙으로 한다. 전체 파일 재작성은 예외적 상황만 허용.
2. 작업 범위·목적·제약을 먼저 명확히 한다.
3. 필요한 코드/정보만 입력·수정 요청한다.
4. 불필요한 반복, 탐색, 포맷팅, 자동화 명령은 최소화한다.
5. 작업 전후에는 SSOT(설계/운영 문서)를 반드시 확인·갱신한다.
6. AI 작업 결과는 항상 직접 확인·검토하고, 문제가 있으면 즉시 수정·피드백한다.
7. 모든 작업/자동화는 "최소 입력, 최대 명확성" 원칙을 따른다.
8. 예외상황(전체 재작성, 구조 변경 등)은 반드시 직접 확인/동의 후 진행한다.

---

## 3. 진행관리/변경 이력

| 날짜       | 작성자      | 변경 내용           | 비고                    |
| ---------- | ----------- | ------------------ | ----------------------- |
| 2025-06-12 | [작성자]    | reference.md 기반 실전 SSOT 반영 | 구조/주요 내용 실전화  |
| 2025-06-17 | [작성자]    | 업종/테마 등락률 계산 로직 변경 | 업종 100%, 테마 662종목 매핑, 날짜별 이력화 |
| 2025-06-17 | [작성자]    | 테마/업종 상세 페이지 구현 | 개별 종목 리스트와 등락률 확인 기능 추가 |
| 2025-06-17 | [작성자]    | 테마 등락률 계산 방식 변경 | 네이버 테마 지수와의 정합성 개선 |
| 2025-06-18 | [작성자]    | krx_collector.py fill_missing_history() 과거 시세 백필 기능 실전 적용, 파생지표(60일 저점, 5일 평균 거래대금) 보충, 안전장치/예외처리/운영 이력 상세화 | 실전 데이터 자동화/분석 파이프라인 확장, 운영 안전성 강화 |
| 2025-06-18 | [작성자]    | UI/차트/상세페이지 개선: 업종/테마 등락률 연동, 종목상세 내부링크, 캔들차트 한국식 컬러 등 최신화 | 실전 운영/UX 개선 |
| 2025-06-18 | [작성자]    | Python import 오류 해결: UI(app.py) 등 모든 실행은 반드시 프로젝트 루트에서 `python -m src.ui.app` 방식으로 실행, sys.path 및 from src.xxx import 패턴 공식화. 뉴스크롤러-UI 연동 정상화. | 운영/실행 표준 SSOT 반영 |
| 2025-06-18 | [작성자]    | 네이버 금융 재무정보 크롤러 개선: 연간/분기 데이터 정확한 구분 처리. 배당금, 매출액, 영업이익 등 주요 재무지표 모두 정상 수집. 예상치(E) 데이터도 정확하게 구분하여 저장. | 재무정보 데이터 품질 개선 |

---

## 4. 기술 스택 및 아키텍처

### 4.1 백엔드
- **언어**: Python
- **프레임워크**: FastAPI (API), Airflow/Prefect (스케줄러)
- **주요 라이브러리**:
  - PyKRX: 주식 시세/기본정보 수집
  - requests, selenium: 크롤링/ETL
  - SQLAlchemy/psycopg2: DB ORM/연결
  - pydantic: 데이터 검증
  - openai/gemini: LLM 연동

### 4.2 프론트엔드
- (MVP 단계 없음, 추후 확장)

### 4.3 파일 구조
```
stock-analytics/
├── config/                  # 환경설정(토큰/API/DB 등)
├── data/                    # 원본/샘플/임시 데이터
├── db/                      # DB 스키마, 마이그레이션, 쿼리
├── scripts/                 # 단독 실행/유틸/테스트 스크립트
├── src/
│   ├── main.py              # 메인 파이프라인
│   ├── collector/           # 데이터 수집/크롤러/ETL
│   ├── processor/           # 데이터 정제/가공/매핑
│   ├── analyzer/            # 정량/정성 분석, 점수화, 랭킹
│   ├── llm/                 # LLM(질의응답/자동 리포트)
│   ├── api/                 # API 서버
│   └── utils/               # 공통 함수/로깅/유틸
├── tests/                   # 유닛/통합 테스트
├── docker/                  # 컨테이너/배포 관련
├── airflow/                 # 워크플로/스케줄러 관리
├── docs/                    # 문서(ERD, API, 알고리즘 등)
├── .env                     # 환경변수
├── requirements.txt         # 의존성 패키지 목록
└── README.md                # 최상위 설명서
```

### 4.4 코드 품질 관리
- Python 타입힌트, mypy, flake8, black 등 적용
- DB 스키마/ERD/문서화 필수, 테스트 코드 분리
- 대량 데이터 인덱싱/파티셔닝 등 성능 최적화

### 4.x 운영/실행 표준 (Python import/실행)

- 모든 파이썬 스크립트/서버 실행은 반드시 프로젝트 루트(예: stock-3)에서 아래와 같이 실행한다:
  - `python -m src.ui.app` (Flask UI)
  - `python -m src.main` (메인 파이프라인 등)
- import는 항상 `from src.xxx` 패턴을 사용한다. (상대 import, 혼용 금지)
- src/ui/app.py 등 스크립트 상단에는 아래 코드로 sys.path를 패치한다:
  ```python
  import sys, os
  sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../')))
  ```
- (참고) `python src/ui/app.py` 등 하위 폴더에서 직접 실행 시 import 오류 발생하므로 금지
- 뉴스크롤러 등 기존 모듈을 UI/서버에 연동할 때도 위 표준을 반드시 따른다
- 본 표준은 실전 운영/테스트/배포 환경에서 일관성, 유지보수성, 협업 효율을 보장하기 위함

---

## 5. 핵심 설계 결정사항

### 5.1 DB 중심 SSOT 구조
- **결정내용**: 모든 데이터/분석/결과는 반드시 DB(관계형, PostgreSQL 권장)에 저장, 각 모듈은 DB에서 읽고 결과도 DB에 저장
- **이유**: 모듈 독립성, 확장성, 유지보수, API/LLM 연동 등 유연성 확보
- **영향**: 각 기능/분석/리포트가 독립적으로 개발·운영·확장 가능, 데이터 신뢰성/일관성 보장

### 5.2 모듈화/컨테이너화/스케줄러 기반
- **결정내용**: 데이터 수집, 정제, 분석, 리포트, LLM 연동 등 각 기능을 독립 파이썬 모듈/컨테이너로 분리, Airflow/Prefect 등으로 자동화
- **이유**: 유지보수/확장/배포/운영 자동화 용이
- **영향**: 신규 기능 추가/변경/롤백/테스트가 쉽고, 실전 운영에 강함

### 5.3 크롤링/외부 API 의존성 관리
- **결정내용**: Selenium 등 크롤링은 웹사이트 변경에 취약, 주기적 모니터링 및 대체 소스(유료 API 등) 로드맵 포함
- **이유**: 데이터 신뢰성/지속성 확보
- **영향**: 크롤러 유지보수, API 전환 등 유연한 구조 필요

### 5.4 뉴스/이슈 데이터 관리 구조
- **결정내용**: 종목/테마별 뉴스/이슈 데이터는 마스터 테이블(Stocks, Themes 등)에 컬럼 추가가 아니라, 별도의 NewsArticles(뉴스 마스터), ArticleStockMap(뉴스-종목 매핑), ArticleThemeMap(뉴스-테마 매핑) 테이블로 분리 관리
- **이유**: 뉴스 데이터는 양이 많고, 종목/테마와 1:N, N:M 관계(한 뉴스가 여러 종목/테마에 매핑될 수 있음). 별도 테이블로 관리해야 확장성, 성능, 분석/검색/LLM 연동, 이력관리, 유지보수 모두에 최적화됨
- **영향**: 뉴스/이슈 크롤러, 분석, LLM, 리포트 등 전체 파이프라인에서 유연하게 활용 가능. SSOT/DB/크롤러/분석/리포트 등 전체 구조에 일관 적용

### 5.5 테마/업종 상세 분석 구조
- **결정내용**: 테마/업종별 상세 페이지에서 소속 종목 리스트와 개별 등락률을 확인할 수 있도록 구현. 시가총액 가중평균 등락률 계산의 정확성 검증을 위한 기반 마련.
- **구현내용**:
  1. 백엔드:
     - `sector_detail_analyzer.py`: 테마/업종별 상세 정보와 종목 리스트 조회
     - `sector_api.py`: REST API 엔드포인트 제공
  2. 프론트엔드:
     - `sector_detail.html`: 상세 정보 표시 페이지
     - DataTables 기반의 종목 리스트 (등락률 기준 정렬)
     - 종목별 네이버 금융 링크 연동
- **이유**: 테마/업종 등락률 계산의 정확성 검증 및 실시간 모니터링 필요
- **영향**: 등락률 계산 오차 발견 시 즉각적인 원인 파악 및 수정 가능

### 5.5 테마/업종 상세 분석 구조
- **2025-06-18 UI/UX/연동 개선:**
  1. 업종/테마 상세페이지 상단 등락률, 차트, 리스트 등 모든 등락률 정보가 동일한 기준(차트API 최신값)으로 연동되도록 개선
  2. 종목명 클릭 시 네이버가 아닌 내부 종목상세(/stock_detail?code=...)로 이동하도록 변경(UX 일관성)
  3. 종목상세 봉차트(캔들차트) 상승=빨강, 하락=파랑(한국식)으로 컬러 일괄 적용
  4. 실전 운영 중 데이터/차트/상세 연동 불일치 발생 시, sector_api.py와 sector_detail.html, app.py의 차트API 연동 로직을 우선 점검할 것
  5. 모든 변경사항은 feature/ui-data-pipeline-20250618 브랜치에 백업 및 롤백 가능

---

## 단계별 진행계획

### 1단계: 데이터 파이프라인 구축 (기반 다지기)
- **목표:** 핵심 데이터(종목, 업종, 테마, 시세, 재무, 뉴스 등)를 안정적으로 수집·DB에 저장, SSOT 체계 확립
- **주요 작업:**
  - DB 스키마 정의 및 초기화 (Stocks, Industries, Themes, StockThemes, DailyStockPrices, FinancialStatements, NewsArticles 등)
  - PyKRX/DART/Selenium 기반 데이터 수집 모듈 개발 및 자동화
- **테스트 계획:**
  - 각 테이블별 샘플 데이터 적재 및 쿼리 정상 동작 확인
  - 수집 모듈별(종목, 시세, 재무, 테마, 뉴스) 단위 테스트 및 DB 적재 결과 검증
  - 데이터 누락/중복/형식 오류 자동 검증 스크립트 실행

### 2단계: 분석 로직 및 자동 리포트 생성 (가치 창출)
- **목표:** 수집 데이터 기반 업종/테마 트렌드, 주도주, 이슈, 투자매력도 등 실전 분석 및 자동 리포트 구현
- **주요 작업:**
  - 업종/테마별 등락률·거래대금 집계, 주도주/이슈 매핑, 투자매력 점수화 등 분석 모듈 개발
  - DailyIndustryTrends, DailyThemeTrends, DailyAnalysisResults 등 분석결과 DB 저장
- **테스트 계획:**
  - 분석 모듈별(트렌드, 주도주, 점수화 등) 단위 테스트 및 결과 DB 적재 검증
  - 샘플 리포트 생성 및 주요 지표(상위 테마/주도주 등) 수치 검증
  - 엣지케이스(데이터 결측, 급등락 등) 처리 검증

### 3단계: LLM 연동 및 서비스 구현 (인사이트 제공)
- **목표:** 분석 데이터 기반 LLM 질의응답, 자동 리포트, 사용자 친화적 서비스 구현
- **주요 작업:**
  - LLM API 연동, 프롬프트 템플릿, 질의응답/리포트 모듈 개발
  - LLMInteractionLogs 등 상호작용 로그 DB화, API 서버/스케줄러/배포 환경 구축
- **테스트 계획:**
  - LLM 질의응답(예시 질문)별 응답 품질 및 데이터 일치성 검증
  - LLM 상호작용 로그 기록 및 분석
  - 전체 파이프라인(수집→분석→LLM) 엔드-투-엔드 통합 테스트

---

## 11. AI 협업 가이드라인

### 11.1 매 작업 시작 시 확인사항
```
현재 상태: [정상 작동하는 기능들 나열]
작업 목표: [1줄로 정확한 목표 정의]
수정 금지: [건드리면 안 되는 코드/파일 명시]
예상 변경: [몇 개 파일, 몇 줄 정도]
타입 체크: [TypeScript 오류 여부 확인]
린트 상태: [ESLint 경고/오류 확인]
```

### 11.2 절대 금지 행동
- ❌ 정상 작동하는 전체 파일 재작성
- ❌ 요청하지 않은 "개선" 또는 "최적화" 작업
- ❌ 테스트 없는 여러 파일 동시 수정
- ❌ 10.1 안정적 코드 섹션의 함수 수정
- ❌ 타입 안전성을 해치는 `any` 타입의 무분별한 사용
- ❌ ESLint 규칙 무시 (특별한 이유 없이 disable 하기)
- ❌ React Hook 의존성 규칙 위반

### 11.3 권장 작업 패턴
1. **단일 집중**: 문제 1개 → 파일 1개 → 수정 완료 → 테스트
2. **도구 우선순위**: edit_file 우선, write_file 최소화
3. **변경 추적**: 수정 전후 비교 설명 필수
4. **상태 업데이트**: 작업 완료 후 코드 상태 맵 갱신
5. **타입 안전성**: TypeScript 오류 해결 우선
6. **코드 품질**: ESLint 경고 해결 및 최적화
7. **성능 고려**: Hook 의존성 및 메모이제이션 최적화

---

## 6. 현재 상태 및 알려진 이슈

### 6.1 ✅ 완료된 기능
- 업종/테마 등락률 계산 및 상세 페이지 구현 (2025-06-17)
- krx_collector.py 과거 시세 백필 및 파생지표 보충 (2025-06-18)
- UI/차트/상세페이지 개선 및 Python import 표준화 (2025-06-18)
- 네이버 금융 재무정보 크롤러 구현 및 연간/분기 데이터 정확한 구분 처리 (2025-06-18)
  - 연간/분기 데이터를 정확하게 구분하여 DB에 저장
  - 배당금, 매출액, 영업이익 등 주요 재무지표 모두 정상 수집
  - 예상치(E) 데이터도 정확하게 구분하여 저장
  - financial_info 테이블에 period 컬럼('Y'/'Q')으로 연간/분기 구분

### 6.2 🔄 진행 중
- [ ] 테마 전체 페이지 확장/최적화(필요시)
- [ ] 테마/업종별 변화 이력 분석 및 리포트 자동화

### 6.4 🚨 알려진 이슈
- 테마정보는 일부 종목(662개)에만 매핑됨(네이버 첫 페이지 기준)
- StockThemes 테이블 구조 변경 시 기존 DB에 ALTER TABLE 필요(트러블슈팅 참고)
- 뉴스/이슈 데이터는 반드시 별도 테이블(NewsArticles, ArticleStockMap, ArticleThemeMap)로 관리해야 함(마스터 테이블 컬럼 추가 금지, 실전 확장성/성능/분석/LLM 연동 등 모든 측면에서 권장)

## 7.3 트러블슈팅/운영가이드 (추가)
- StockThemes 테이블 구조 변경(예: collected_at 컬럼 추가) 시 기존 DB에 ALTER TABLE로 컬럼 추가 필요
- 업종/테마 크롤러 실행 후 scripts/db_check.py로 매핑 현황(총 종목수, 업종/테마 매핑 종목수) 반드시 검증
- 테마정보는 네이버 첫 페이지만 수집 시 일부 종목만 매핑됨. 전체 테마 확장 필요시 크롤러 수정

---

# 업종/테마 등락률 계산 로직 변경 (2025-06-17)

## 변경 내용
1. 업종/테마 등락률 계산 로직을 시가총액 가중평균 방식으로 변경
   - 기존: 단순 평균 방식
   - 변경: `SUM(price_change_ratio * market_cap) / SUM(market_cap)`
   - 네이버 금융과 동일한 계산 방식 적용

2. 코드 구조 개선
   - `theme_industry_collector.py` 제거
   - `sector_theme_analyzer.py`로 기능 통합
   - 실시간 분석과 DB 저장 기능을 하나의 모듈로 통합
   - `save_to_db` 파라미터로 DB 저장 여부 선택 가능

3. 성과 데이터 저장 구조
   - DB: `theme_industry.db`
   - 테이블:
     - `theme_daily_performance`: 테마별 일간 성과
     - `industry_daily_performance`: 업종별 일간 성과
   - 저장 정보:
     - 시가총액 가중평균 등락률
     - 거래량, 거래대금, 시가총액 합계
     - 상승/하락/보합 종목 수
     - 시가총액 상위 5종목(리더주)

## 실행 순서
1. `krx_collector.py` 실행: 최신 주가 데이터 수집
2. `sector_theme_analyzer.py` 실행: 업종/테마별 등락률 계산 및 저장

## 사용 예시
```python
# 실시간 조회만 할 경우
results = get_industry_performance(date, save_to_db=False)

# DB에 저장하면서 조회할 경우
results = get_industry_performance(date, save_to_db=True)

# 일간 성과 일괄 업데이트
update_daily_performance(date)
```

## 참고사항
- 업종/테마별 등락률은 시가총액 가중평균으로 계산
- 업종/테마 내 종목들의 시가총액이 클수록 해당 종목의 등락률이 더 큰 영향을 미침
- 네이버 금융 등 시장 표준과 동일한 계산 방식 사용

---

## 변경 이력

### 2025-06-17
- 업종과 테마의 등락률 순위 정보 추가
  - theme_daily_performance와 industry_daily_performance 테이블에 rank 컬럼 추가
  - 등락률 기준으로 순위 자동 계산 및 저장 기능 구현
  - 업종은 시가총액 가중평균 등락률 기준, 테마는 단순평균 등락률 기준으로 순위 산출
  - sector_theme_analyzer.py의 get_industry_performance()와 get_theme_performance() 함수에 순위 계산 로직 추가

### 2024-03-21 테마 등락률 계산 방식 변경
- 변경 내용: 테마 등락률 계산을 시가총액 가중평균에서 단순 평균으로 변경
- 변경 이유: 네이버 테마 지수와의 정합성 개선
- 영향 범위: 테마 등락률 계산 로직만 변경 (업종 등락률은 기존 방식 유지)
- 관련 파일: src/analyzer/sector_theme_analyzer.py
- 주요 변경사항:
  * 테마 등락률을 단순 평균으로 계산하도록 변경
  * 기존 시가총액 가중평균은 market_cap_weighted_ratio 컬럼으로 보존 (참고용)
  * theme_daily_performance 테이블 스키마 수정
  * 정렬 기준을 단순 평균 등락률로 변경

### 2025-06-18
- krx_collector.py에 과거 일별 시세 누락분을 pykrx로 보충하는 fill_missing_history() 기능 추가
  - 목적: DailyStocks 등 마스터 DB에 60일 등 과거 시세 데이터가 부족할 때, pykrx로 누락분만 안전하게 보충
  - 사용법: `python src/collector/krx_collector.py --backfill` (필요시 수동 실행)
  - 기존 collector 메인 기능과 완전히 분리되어, 평소에는 영향 없음
  - 이미 DB에 있는 날짜/종목 데이터는 건너뜀(중복 저장 방지)
  - 신규 상장주 등 60일 미만 데이터는 존재하는 만큼만 저장
  - pykrx 호출 실패/중단 시에도 기존 데이터는 유지됨
  - SSOT 및 운영 문서에 사용법/목적/주의사항 명확히 기록

---

# 과거 시세 데이터 백필 및 파생지표 보충 기능 (2025-06-18)

## 주요 내용
- `src/collector/krx_collector.py`에 fill_missing_history() 함수 추가, `--backfill` 옵션으로 과거 60영업일(또는 지정 범위) 누락 일별 시세를 pykrx로 안전하게 보충
- 신규 상장주 등 60일 미만 데이터는 존재하는 만큼만 저장, 이미 DB에 있는 데이터는 건너뜀(중복 저장/오염 방지)
- 거래대금 컬럼명 이슈(예: '거래대금', '거래대금(백만)', '거래대금(원)', '거래대금(천원)' 등) 발생 시 다양한 컬럼명 체크 및 KeyError 예외처리로 실전 운영 안전성 확보
- fill_missing_history()는 collector 메인 기능과 완전히 분리, 최초 1회 또는 누락 발생 시에만 수동 실행(일상적 자동화와 분리)
- 파생지표(60일 저점, 5일 평균 거래대금) 산출 및 저점반등주 추출 파이프라인과 연동, 실전 데이터 품질 보장
- pykrx 호출 실패/중단 시에도 기존 데이터는 유지, 부분 성공/실패 모두 로그로 남김

## 사용법
- 과거 시세 백필: `python src/collector/krx_collector.py --backfill`
- (최초 1회 또는 누락 발생 시에만 실행, 평소 collector 자동화와 분리)
- 실행 로그에서 "XX개 날짜 보충 완료" 등 정상 처리 여부 확인
- 예외 발생 시 KeyError 등 상세 로그로 원인 파악 가능

## 실전 운영 가이드/트러블슈팅
- fill_missing_history() 실행 전후 DB(특히 DailyStocks, 파생지표 테이블) 데이터 정상 적재 여부 확인
- 거래대금 컬럼명 이슈 발생 시 다양한 컬럼명 체크/예외처리 코드 유지 필요
- 신규 상장주/거래정지주 등 특수 케이스는 존재하는 데이터만 저장, 누락/오류는 무시(운영 중단 방지)
- pykrx API 장애/지연 시 부분 저장/재시도 가능, 기존 데이터 오염 없음
- 파생지표(60일 저점, 5일 평균 거래대금) 및 저점반등주 추출 파이프라인과 연동하여 실전 데이터 품질 보장
- 모든 변경/운영 이력은 SSOT.md 및 changelog.md에 즉시 기록

## 연관 파이프라인/분석
- fill_missing_history()로 보충된 데이터는 저점반등주, 파생지표, 업종/테마 분석 등 실전 자동화 파이프라인 전체에 즉시 반영됨
- 실전 데이터 품질/운영 안전성/확장성 모두 강화

---
